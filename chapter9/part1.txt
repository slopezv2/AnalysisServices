Links:
https://docs.microsoft.com/en-us/analysis-services/tabular-models/directquery-mode-ssas-tabular?view=asallproducts-allversions
https://www.sqlbi.com/whitepapers/directquery-in-analysis-services-2016/
https://www.sqlbi.com/tv/directquery-in-analysis-services-best-practices-performance-use-cases/

In-memory model (VertiPaq)
During processing, the SSAS engine will execute a SELECT statement over the entire table, reading all
the rows and performing its own processing steps. This means you need to optimize your data source for
a huge single scan of the table. Indexes are useless, and partitioning, if needed, should be aligned with
partitions defined in your SSAS solution.

DirectQuery model
If the same data need to be used by DirectQuery, then your table will be accessed at least once for each
query and, out of the whole table, only a small subset of it might be needed for the query. In this case,
you need to optimize the SQL model to quickly answer the queries generated by DirectQuery. This
includes creating the correct indexes on the table, and probably partitioning it to reduce I/O activity
during query execution. 

In T-SQL, you can use table, views, and table-valued
functions; the only limitation is on stored procedures.

This default limit of 1 million rows is the same used for models created by Power BI Desktop. This limit is
present to prevent huge amount of data being moved between the engines. This is a safety feature, but it
can result in queries that cannot be executed. For this reason, you might want to increase this setting on 
Page 16
your SSAS instance

in msmdsrv.ini:
<ConfigurationSettings>
. . .
<DAX>
 <DQ>
 <MaxIntermediateRowsetSize>1000000
 </MaxIntermediateRowsetSize>
 </DQ>
</DAX>
. . .

e. As a rule of thumb, this setting should be higher than the larger dimension in a star schema
model. For example, if you have 4 millions products and 8 million customers, you should increase the
MaxIntermediateRowsetSize setting to 10 million

Using a value that is too high (such as 100 million) could exhaust
the memory and/or timeout the query before the limit is reached, so a lower limit helps avoid such a
critical condition.

Optimized DAX formulas:
ABS, ACOS, ACOT, AND, ASIN, ATAN, BLANK, CEILING, CONCATENATE, COS, COT,
CURRENCY, DATE, DATEDIFF, DATEVALUE, DAY, DEGREES, DIVIDE, EDATE,
EOMONTH, EXACT, EXP, FALSE, FIND, HOUR, IF, INT, ISBLANK, ISO.CEILING,
KEEPFILTERS, LEFT, LEN, LN, LOG, LOG10, LOWER, MAX, MID, MIN, MINUTE,
MOD, MONTH, MROUND, NOT, NOW, OR, PI, POWER, QUOTIENT, RADIANS, RAND,
RELATED, REPT, RIGHT, ROUND, ROUNDDOWN, ROUNDUP, SEARCH, SECOND, SIGN,
SIN, SQRT, SQRTPI, SUBSTITUTE, SWITCH, TAN, TIME, TIMEVALUE, TODAY, TRIM,
TRUE, TRUNC, UNICODE, UPPER, USERNAME, USERELATIONSHIP, VALUE, WEEKDAY,
WEEKNUM, YEAR.

Not available in RLS:
ALL, ALLEXCEPT, ALLNOBLANKROW, ALLSELECTED, AVERAGE, AVERAGEA, AVERAGEX,
CALCULATE, CALCULATETABLE, COUNT, COUNTA, COUNTAX, COUNTROWS, COUNTX,
DISTINCT, DISTINCTCOUNT, FILTER, FILTERS, HASONEFILTER, HASONEVALUE,
ISCROSSFILTERED, ISFILTERED, MAXA, MAXX, MIN, MINA, MINX, RELATEDTABLE,
STDEV.P, STDEV.S, STDEVX.P, STDEVX.S, SUM, SUMX, VALUES, VAR.P, VAR.S,
VARX.P, VARX.S.

Example:
DAX:
DEFINE
 MEASURE Sales[Amt] =
 SUMX ( Sales, Sales[Quantity] * Sales[Unit Price] )
EVALUATE
SUMMARIZECOLUMNS ( Product[Color], "Amt", [Amt] )

in SQL:
SELECT TOP (1000001)
 t0.ProductColor,
 SUM ( t0.PriceMultipliedByQuantity ) AS PriceMultipliedByQuantity
FROM
 (SELECT
 Sales.[Quantity] AS Quantity,
 Sales.[Unit Price] AS [Unit Price],
 Product.[Color] AS ProductColor,
 (Sales.[Quantity] * Sales.[Unit Price]) AS PriceMultipliedByQuantity
 FROM
 Sales
 LEFT OUTER JOIN Product
 ON Sales.[ProductKey] = Product.[ProductKey]
 ) AS [t0]
GROUP BY
 t0.ProductColor

Generally, a columnstore index is a good solution for optimizing SQL Server database for DirectQuery
